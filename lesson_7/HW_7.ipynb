{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aa59ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем запрограммировать простую рекурентную сеть\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "198da5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e426721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181467, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bb183de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cd39cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', 'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'z', 'x', 'c', 'v', 'b', 'n', 'm', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '❤']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "en_letters = ['q', 'w','e','r','t','y','u','i','o','p','a'\n",
    "          ,'s','d','f','g','h','j','k','l','z','x','c','v','b','n','m','1','2','3','4','5','6','7','8','9','0','❤']\n",
    "ru = 'ёйцукенгшщзхъфывапролджэячсмитьбю'\n",
    "ru_letters = set(ru)\n",
    "print(len(ru_letters))\n",
    "print(en_letters)\n",
    "print('re' not in en_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af42268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7ea8b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\\\', '%', '&', '-', '+', '[', '^', '!', \"'\", '}', ',', '/', ';', '~', '<', '(', '?', '#', '\"', '*', '>', ':', '|', '`', '_', ')', '$', '{', ']', '@', '.', '='}\n"
     ]
    }
   ],
   "source": [
    "# punctuation.append('❤')\n",
    "exclude = set(punctuation)\n",
    "# exclude.append('❤')\n",
    "print(exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f8adf",
   "metadata": {},
   "source": [
    "очищаю текст от слов несущих малое значение, от английских символов т.к. это ник неймы не несущие никакого смысла, 'не' привязываю к следующему после частицы идущего слова, чтоб не потерять смысл предложения, привожу слова к нормальной форме при помощи библиотеки pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f18972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = \"\".join(c for c in txt if c not in letter)\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d37446de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>уезжаааааааать тожена уезжать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ребята девчата кино любовь завтра вотэтолюбовь</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ктоненавидеть пробка ретвит</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>хотеться котлета покиевск запретный плод</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>босапоп есбосан бояться мороз</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>манчестер час играть ян дом</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>жаба пришол остаться транспорт правда девчёнка...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>момент мальчик маньяк ражик гладить рука феликс</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>простонеудачик поцарапать экран телефон</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>хахаа запомниться надолго</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>красава тебен сомневаться</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>мартовский путёвка дорожать глаз пара оо</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>прошлый месяц вообщить</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>привет самый хороший друг извращенобольный фан...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>придумать новый</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>увеличение лимит бесплатный пополнение сделать...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>тожить лах завтрана идти</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>голован прекращать болеть пойти температурка п...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>крайне культурный друг разговорнезнакомый кузо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>работать отмена встряхивание</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>австрия ждеееть последний формальность уладить...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>одноклассник наня психанулон плакать потомнить...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>парнит понять</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>оуовать рада ещеть продажа</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>прогноз погода ит близкий</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>пара сотрудничество положительный эмоция компа...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>красивый ян</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>пособие применение рука</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>начальница рассказывать свадьба минута чтоть в...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>гггггга момент милаявсё тайлера оч кластный ма...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  class\n",
       "0    0                      уезжаааааааать тожена уезжать      0\n",
       "1    1     ребята девчата кино любовь завтра вотэтолюбовь      1\n",
       "2    2                        ктоненавидеть пробка ретвит      0\n",
       "3    3           хотеться котлета покиевск запретный плод      1\n",
       "4    4                      босапоп есбосан бояться мороз      1\n",
       "5    5                        манчестер час играть ян дом      0\n",
       "6    6  жаба пришол остаться транспорт правда девчёнка...      1\n",
       "7    7    момент мальчик маньяк ражик гладить рука феликс      1\n",
       "8    8            простонеудачик поцарапать экран телефон      0\n",
       "9    9                          хахаа запомниться надолго      1\n",
       "10  10                          красава тебен сомневаться      1\n",
       "11  11           мартовский путёвка дорожать глаз пара оо      0\n",
       "12  12                             прошлый месяц вообщить      0\n",
       "13  13  привет самый хороший друг извращенобольный фан...      1\n",
       "14  14                                    придумать новый      1\n",
       "15  15  увеличение лимит бесплатный пополнение сделать...      1\n",
       "16  16                           тожить лах завтрана идти      1\n",
       "17  17  голован прекращать болеть пойти температурка п...      1\n",
       "18  18  крайне культурный друг разговорнезнакомый кузо...      1\n",
       "19  19                       работать отмена встряхивание      0\n",
       "20  20  австрия ждеееть последний формальность уладить...      1\n",
       "21  21  одноклассник наня психанулон плакать потомнить...      1\n",
       "22  22                                      парнит понять      1\n",
       "23  23                         оуовать рада ещеть продажа      0\n",
       "24  24                          прогноз погода ит близкий      1\n",
       "25  25  пара сотрудничество положительный эмоция компа...      1\n",
       "26  26                                        красивый ян      1\n",
       "27  27                            пособие применение рука      1\n",
       "28  28  начальница рассказывать свадьба минута чтоть в...      1\n",
       "29  29  гггггга момент милаявсё тайлера оч кластный ма...      1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ec9ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab2index = {\"\":0, \"UNK\":1}\n",
    "# words = [\"\", \"UNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec2a9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, 'UNK': 1, 'red': 24, 'blue': 12, 'green': 23}\n",
      "['', 'UNK', 'red', 'blue', 'red', 'green', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'green', 'red']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# a = ['red', 'blue', 'red', 'green', 'blue', 'blue']\n",
    "# counts = Counter()\n",
    "# counts.update(a)\n",
    "# # print(len(counts.keys()))\n",
    "# # print(list(counts.keys())[1])\n",
    "# # print(counts['red'])\n",
    "# word = a[0]\n",
    "# vocab2index[word] = len(words)\n",
    "# words.append(word)\n",
    "# print(vocab2index)\n",
    "# print(words)\n",
    "# # Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5b0df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2651eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 155836\n",
      "num_words after: 45689\n"
     ]
    }
   ],
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values\n",
    "\n",
    "counts = Counter()\n",
    "for sequence in text_corpus_train:\n",
    "    counts.update(sequence.split())\n",
    "\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))\n",
    "    \n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f036383c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "183e0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels, w2index, used_length):\n",
    "        self._txts = txts\n",
    "        self._labels = labels\n",
    "        self._length = used_length\n",
    "        self._w2index = w2index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    @lru_cache(50000)\n",
    "    def encode_sentence(self, txt):\n",
    "        encoded = np.zeros(self._length, dtype=int)\n",
    "        enc1 = np.array([self._w2index.get(word, self._w2index[\"UNK\"]) for word in txt.split()])\n",
    "        length = min(self._length, len(enc1))\n",
    "        encoded[:length] = enc1[:length]\n",
    "        return encoded, length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded, length = self.encode_sentence(self._txts[index])\n",
    "        return torch.from_numpy(encoded.astype(np.int32)), self._labels[index], length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae6f4f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i.split()) for i in text_corpus_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6535233",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values\n",
    "\n",
    "train_dataset = TwitterDataset(text_corpus_train, y_train, vocab2index, 27)\n",
    "valid_dataset = TwitterDataset(text_corpus_valid, y_val, vocab2index, 27)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d0c1a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        rnn_out, (ht, ct) = self.rnn(x)\n",
    "        return self.linear(rnn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13d33a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_init = RNNFixedLen(len(vocab2index), 30, 20)\n",
    "optimizer = torch.optim.Adam(rnn_init.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf76bb",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afd5f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3148f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a780aaecb840aaa95f2db1b362a3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 valid_loss 114.20539093017578\n",
      "Epoch 1 valid_loss 113.68492889404297\n",
      "Epoch 2 valid_loss 113.16081237792969\n",
      "Epoch 3 valid_loss 115.48741912841797\n",
      "Epoch 4 valid_loss 117.35490417480469\n",
      "Epoch 5 valid_loss 117.39289855957031\n",
      "Epoch 6 valid_loss 116.42377471923828\n",
      "Epoch 7 valid_loss 120.84660339355469\n",
      "Epoch 8 valid_loss 121.12635803222656\n",
      "Epoch 9 valid_loss 122.92884063720703\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(epochs)):  \n",
    "    rnn_init.train()\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        inputs, labels, lengths = data[0], data[1], data[2]\n",
    "        inputs = inputs.long()\n",
    "        labels = labels.long().view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = rnn_init(inputs, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    rnn_init.eval()\n",
    "    loss_accumed = 0\n",
    "    for X, y, lengths in valid_loader:\n",
    "        X = X.long()\n",
    "        y = y.long().view(-1, 1)\n",
    "        output = rnn_init(X, lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss_accumed += loss\n",
    "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c890e30",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39a1910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(lstm_out)\n",
    "    \n",
    "lstm_init = LSTMFixedLen(len(vocab2index), 30, 20)\n",
    "optimizer = torch.optim.Adam(lstm_init.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f865cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72037ae8425f4ea78534b56a73866600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 valid_loss 113.22369384765625\n",
      "Epoch 1 valid_loss 112.22395324707031\n",
      "Epoch 2 valid_loss 113.3219223022461\n",
      "Epoch 3 valid_loss 114.02628326416016\n",
      "Epoch 4 valid_loss 117.17424011230469\n",
      "Epoch 5 valid_loss 118.502197265625\n",
      "Epoch 6 valid_loss 119.434814453125\n",
      "Epoch 7 valid_loss 124.0313720703125\n",
      "Epoch 8 valid_loss 123.37696838378906\n",
      "Epoch 9 valid_loss 124.91738891601562\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(epochs)):  \n",
    "    lstm_init.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels, lengths = data[0], data[1], data[2]\n",
    "        inputs = inputs.long()\n",
    "        labels = labels.long().view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = lstm_init(inputs, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    lstm_init.eval()\n",
    "    loss_accumed = 0\n",
    "    for X, y, lengths in valid_loader:\n",
    "        X = X.long()\n",
    "        y = y.long().view(-1, 1)\n",
    "        output = lstm_init(X, lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss_accumed += loss\n",
    "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c6f96",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46225d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUFixedLen(nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        gru_out, (ht, ct) = self.gru(x)\n",
    "        return self.linear(gru_out)\n",
    "    \n",
    "gru_init = GRUFixedLen(len(vocab2index), 30, 20)\n",
    "optimizer = torch.optim.Adam(gru_init.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0e35870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3796cd300044b0965c519cdbb9f3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 valid_loss 113.19703674316406\n",
      "Epoch 1 valid_loss 113.18024444580078\n",
      "Epoch 2 valid_loss 114.15181732177734\n",
      "Epoch 3 valid_loss 115.62777709960938\n",
      "Epoch 4 valid_loss 117.05768585205078\n",
      "Epoch 5 valid_loss 120.30059051513672\n",
      "Epoch 6 valid_loss 119.49751281738281\n",
      "Epoch 7 valid_loss 120.0285415649414\n",
      "Epoch 8 valid_loss 122.36158752441406\n",
      "Epoch 9 valid_loss 123.08397674560547\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(epochs)):  \n",
    "    gru_init.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels, lengths = data[0], data[1], data[2]\n",
    "        inputs = inputs.long()\n",
    "        labels = labels.long().view(-1, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = gru_init(inputs, lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    gru_init.eval()\n",
    "    loss_accumed = 0\n",
    "    for X, y, lengths in valid_loader:\n",
    "        X = X.long()\n",
    "        y = y.long().view(-1, 1)\n",
    "        output = gru_init(X, lengths)\n",
    "        loss = criterion(output, y)\n",
    "        loss_accumed += loss\n",
    "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
    "\n",
    "print('Training is finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
